"""Threat enrichment engine for contextual analysis."""

import asyncio
import logging
from typing import Dict, List, Any, Optional, Set
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from collections import defaultdict

from .threat_intel_manager import ThreatMatch, ThreatIndicator, ThreatType, ThreatLevel


logger = logging.getLogger(__name__)


@dataclass
class ThreatContext:
    """Enriched threat context information."""
    
    # Attack information
    attack_patterns: List[str] = field(default_factory=list)
    tactics: List[str] = field(default_factory=list)
    techniques: List[str] = field(default_factory=list)
    
    # Malware information
    malware_families: List[str] = field(default_factory=list)
    campaigns: List[str] = field(default_factory=list)
    
    # Actor information
    threat_actors: List[str] = field(default_factory=list)
    attribution: Dict[str, float] = field(default_factory=dict)
    
    # Geographic information
    source_countries: List[str] = field(default_factory=list)
    target_countries: List[str] = field(default_factory=list)
    
    # Temporal information
    first_seen_global: Optional[datetime] = None
    last_seen_global: Optional[datetime] = None
    activity_timeline: List[Dict[str, Any]] = field(default_factory=list)
    
    # Relationship information
    related_indicators: List[str] = field(default_factory=list)
    infrastructure_links: List[str] = field(default_factory=list)
    
    # Risk assessment
    risk_factors: List[str] = field(default_factory=list)
    impact_assessment: Dict[str, Any] = field(default_factory=dict)
    
    # Contextual metadata
    confidence_score: float = 0.0
    enrichment_sources: List[str] = field(default_factory=list)
    
    def to_dict(self) -> Dict[str, Any]:
        """Convert context to dictionary."""
        return {
            'attack_patterns': self.attack_patterns,
            'tactics': self.tactics,
            'techniques': self.techniques,
            'malware_families': self.malware_families,
            'campaigns': self.campaigns,
            'threat_actors': self.threat_actors,
            'attribution': self.attribution,
            'source_countries': self.source_countries,
            'target_countries': self.target_countries,
            'first_seen_global': self.first_seen_global.isoformat() if self.first_seen_global else None,
            'last_seen_global': self.last_seen_global.isoformat() if self.last_seen_global else None,
            'activity_timeline': self.activity_timeline,
            'related_indicators': self.related_indicators,
            'infrastructure_links': self.infrastructure_links,
            'risk_factors': self.risk_factors,
            'impact_assessment': self.impact_assessment,
            'confidence_score': self.confidence_score,
            'enrichment_sources': self.enrichment_sources
        }


class ThreatEnrichmentEngine:
    """Engine for enriching threat intelligence with contextual information."""
    
    def __init__(self):
        """Initialize threat enrichment engine."""
        self.logger = logging.getLogger(__name__)
        
        # Knowledge bases
        self.mitre_attack_db = self._load_mitre_attack_db()
        self.malware_db = self._load_malware_db()
        self.actor_db = self._load_actor_db()
        self.campaign_db = self._load_campaign_db()
        
        # Enrichment cache
        self.enrichment_cache = {}
        self.cache_ttl = timedelta(hours=24)
    
    async def enrich_matches(self, matches: List[ThreatMatch]) -> Dict[str, Any]:
        """Enrich threat matches with contextual information."""
        if not matches:
            return {}\n        \n        enriched_context = {\n            'summary': await self._generate_summary(matches),\n            'threat_landscape': await self._analyze_threat_landscape(matches),\n            'attack_analysis': await self._analyze_attack_patterns(matches),\n            'risk_assessment': await self._assess_risk(matches),\n            'recommendations': await self._generate_recommendations(matches),\n            'enriched_matches': []\n        }\n        \n        # Enrich individual matches\n        for match in matches:\n            enriched_match = await self._enrich_single_match(match)\n            enriched_context['enriched_matches'].append(enriched_match)\n        \n        return enriched_context\n    \n    async def _enrich_single_match(self, match: ThreatMatch) -> Dict[str, Any]:\n        \"\"\"Enrich a single threat match.\"\"\"\n        indicator = match.indicator\n        \n        # Check cache first\n        cache_key = f\"{indicator.indicator_id}_{indicator.value}\"\n        if cache_key in self.enrichment_cache:\n            cached_entry = self.enrichment_cache[cache_key]\n            if datetime.now() - cached_entry['timestamp'] < self.cache_ttl:\n                return {\n                    'match': match.to_dict(),\n                    'context': cached_entry['context'].to_dict()\n                }\n        \n        # Perform enrichment\n        context = ThreatContext()\n        \n        # Enrich based on indicator type and threat type\n        await self._enrich_malware_context(indicator, context)\n        await self._enrich_attack_context(indicator, context)\n        await self._enrich_actor_context(indicator, context)\n        await self._enrich_campaign_context(indicator, context)\n        await self._enrich_infrastructure_context(indicator, context)\n        await self._enrich_temporal_context(indicator, context)\n        \n        # Calculate overall confidence\n        context.confidence_score = self._calculate_enrichment_confidence(context)\n        \n        # Cache the result\n        self.enrichment_cache[cache_key] = {\n            'context': context,\n            'timestamp': datetime.now()\n        }\n        \n        return {\n            'match': match.to_dict(),\n            'context': context.to_dict()\n        }\n    \n    async def _enrich_malware_context(self, indicator: ThreatIndicator, context: ThreatContext):\n        \"\"\"Enrich with malware-specific context.\"\"\"\n        if indicator.threat_type == ThreatType.MALWARE:\n            # Extract malware families from tags and description\n            for family in self.malware_db.get('families', []):\n                if any(family.lower() in tag.lower() for tag in indicator.tags):\n                    context.malware_families.append(family)\n                if family.lower() in indicator.description.lower():\n                    context.malware_families.append(family)\n            \n            # Add malware-specific risk factors\n            if indicator.ioc_type.value == 'file_hash':\n                context.risk_factors.extend([\n                    'Executable file detected',\n                    'Potential malware infection',\n                    'File-based threat'\n                ])\n            \n            context.enrichment_sources.append('malware_db')\n    \n    async def _enrich_attack_context(self, indicator: ThreatIndicator, context: ThreatContext):\n        \"\"\"Enrich with MITRE ATT&CK context.\"\"\"\n        # Map IOC types to common attack techniques\n        ioc_technique_map = {\n            'ip_address': ['T1071.001', 'T1090', 'T1102'],  # C2, Proxy, Web Service\n            'domain': ['T1071.001', 'T1102', 'T1583.001'],  # C2, Web Service, Domain\n            'url': ['T1071.001', 'T1102', 'T1566.002'],     # C2, Web Service, Phishing\n            'file_hash': ['T1055', 'T1059', 'T1204.002'],   # Injection, Command, Malicious File\n            'email': ['T1566.001', 'T1566.002'],            # Spearphishing\n            'registry_key': ['T1112', 'T1547.001'],         # Registry, Registry Run Keys\n            'process_name': ['T1055', 'T1059', 'T1036']     # Injection, Command, Masquerading\n        }\n        \n        techniques = ioc_technique_map.get(indicator.ioc_type.value, [])\n        context.techniques.extend(techniques)\n        \n        # Map techniques to tactics\n        for technique in techniques:\n            tactics = self.mitre_attack_db.get('techniques', {}).get(technique, {}).get('tactics', [])\n            context.tactics.extend(tactics)\n        \n        if techniques:\n            context.enrichment_sources.append('mitre_attack')\n    \n    async def _enrich_actor_context(self, indicator: ThreatIndicator, context: ThreatContext):\n        \"\"\"Enrich with threat actor context.\"\"\"\n        # Check if indicator matches known actor IOCs\n        for actor_name, actor_data in self.actor_db.get('actors', {}).items():\n            actor_iocs = actor_data.get('iocs', [])\n            \n            # Simple matching (can be enhanced with fuzzy matching)\n            if indicator.value in actor_iocs:\n                context.threat_actors.append(actor_name)\n                context.attribution[actor_name] = 0.8\n                \n                # Add actor-specific context\n                context.source_countries.extend(actor_data.get('countries', []))\n                context.tactics.extend(actor_data.get('tactics', []))\n                \n                context.enrichment_sources.append('actor_db')\n    \n    async def _enrich_campaign_context(self, indicator: ThreatIndicator, context: ThreatContext):\n        \"\"\"Enrich with campaign context.\"\"\"\n        # Check campaign associations\n        for campaign_name, campaign_data in self.campaign_db.get('campaigns', {}).items():\n            campaign_iocs = campaign_data.get('iocs', [])\n            \n            if indicator.value in campaign_iocs:\n                context.campaigns.append(campaign_name)\n                \n                # Add campaign timeline\n                context.activity_timeline.append({\n                    'campaign': campaign_name,\n                    'start_date': campaign_data.get('start_date'),\n                    'end_date': campaign_data.get('end_date'),\n                    'description': campaign_data.get('description', '')\n                })\n                \n                context.enrichment_sources.append('campaign_db')\n    \n    async def _enrich_infrastructure_context(self, indicator: ThreatIndicator, context: ThreatContext):\n        \"\"\"Enrich with infrastructure context.\"\"\"\n        if indicator.ioc_type.value in ['ip_address', 'domain', 'url']:\n            # Add infrastructure-specific risk factors\n            context.risk_factors.extend([\n                'Network-based indicator',\n                'Potential C2 infrastructure',\n                'Network communication threat'\n            ])\n            \n            # Check for related infrastructure\n            # This would typically involve DNS resolution, WHOIS data, etc.\n            # For now, we'll add placeholder logic\n            if indicator.ioc_type.value == 'domain':\n                context.infrastructure_links.append(f\"Subdomain analysis for {indicator.value}\")
                context.risk_factors.append('Domain-based threat')\n            \n            context.enrichment_sources.append('infrastructure_analysis')\n    \n    async def _enrich_temporal_context(self, indicator: ThreatIndicator, context: ThreatContext):\n        \"\"\"Enrich with temporal context.\"\"\"\n        context.first_seen_global = indicator.first_seen\n        context.last_seen_global = indicator.last_seen\n        \n        # Analyze activity patterns\n        age = datetime.now() - indicator.first_seen\n        \n        if age.days < 1:\n            context.risk_factors.append('Recently discovered threat')\n        elif age.days < 7:\n            context.risk_factors.append('Recent threat activity')\n        elif age.days > 365:\n            context.risk_factors.append('Long-term persistent threat')\n        \n        context.enrichment_sources.append('temporal_analysis')\n    \n    async def _generate_summary(self, matches: List[ThreatMatch]) -> Dict[str, Any]:\n        \"\"\"Generate summary of threat matches.\"\"\"\n        total_matches = len(matches)\n        \n        # Count by threat type\n        threat_types = defaultdict(int)\n        threat_levels = defaultdict(int)\n        sources = defaultdict(int)\n        \n        for match in matches:\n            threat_types[match.indicator.threat_type.value] += 1\n            threat_levels[match.indicator.threat_level.value] += 1\n            sources[match.indicator.source] += 1\n        \n        # Calculate average risk score\n        avg_risk = sum(match.risk_score for match in matches) / total_matches if total_matches > 0 else 0\n        \n        return {\n            'total_matches': total_matches,\n            'average_risk_score': round(avg_risk, 2),\n            'threat_types': dict(threat_types),\n            'threat_levels': dict(threat_levels),\n            'sources': dict(sources),\n            'highest_risk_match': max(matches, key=lambda m: m.risk_score).to_dict() if matches else None\n        }\n    \n    async def _analyze_threat_landscape(self, matches: List[ThreatMatch]) -> Dict[str, Any]:\n        \"\"\"Analyze the overall threat landscape.\"\"\"\n        landscape = {\n            'primary_threats': [],\n            'attack_vectors': [],\n            'geographic_distribution': {},\n            'temporal_patterns': {}\n        }\n        \n        # Identify primary threats\n        threat_counts = defaultdict(int)\n        for match in matches:\n            threat_counts[match.indicator.threat_type.value] += 1\n        \n        landscape['primary_threats'] = sorted(\n            threat_counts.items(), \n            key=lambda x: x[1], \n            reverse=True\n        )[:5]\n        \n        # Identify attack vectors\n        vector_counts = defaultdict(int)\n        for match in matches:\n            ioc_type = match.indicator.ioc_type.value\n            if ioc_type in ['ip_address', 'domain', 'url']:\n                vector_counts['network'] += 1\n            elif ioc_type == 'file_hash':\n                vector_counts['file'] += 1\n            elif ioc_type == 'email':\n                vector_counts['email'] += 1\n            else:\n                vector_counts['other'] += 1\n        \n        landscape['attack_vectors'] = dict(vector_counts)\n        \n        return landscape\n    \n    async def _analyze_attack_patterns(self, matches: List[ThreatMatch]) -> Dict[str, Any]:\n        \"\"\"Analyze attack patterns from matches.\"\"\"\n        patterns = {\n            'common_techniques': [],\n            'attack_chains': [],\n            'persistence_mechanisms': [],\n            'evasion_techniques': []\n        }\n        \n        # This would involve more sophisticated analysis\n        # For now, provide basic pattern recognition\n        \n        technique_counts = defaultdict(int)\n        for match in matches:\n            # Extract techniques from tags and description\n            for tag in match.indicator.tags:\n                if tag.startswith('T'):\n                    technique_counts[tag] += 1\n        \n        patterns['common_techniques'] = sorted(\n            technique_counts.items(),\n            key=lambda x: x[1],\n            reverse=True\n        )[:10]\n        \n        return patterns\n    \n    async def _assess_risk(self, matches: List[ThreatMatch]) -> Dict[str, Any]:\n        \"\"\"Assess overall risk from threat matches.\"\"\"\n        if not matches:\n            return {'overall_risk': 'LOW', 'risk_score': 0.0}\n        \n        # Calculate weighted risk score\n        total_risk = sum(match.risk_score * match.confidence_score for match in matches)\n        total_weight = sum(match.confidence_score for match in matches)\n        \n        weighted_risk = total_risk / total_weight if total_weight > 0 else 0\n        \n        # Determine risk level\n        if weighted_risk >= 8.0:\n            risk_level = 'CRITICAL'\n        elif weighted_risk >= 6.0:\n            risk_level = 'HIGH'\n        elif weighted_risk >= 4.0:\n            risk_level = 'MEDIUM'\n        else:\n            risk_level = 'LOW'\n        \n        return {\n            'overall_risk': risk_level,\n            'risk_score': round(weighted_risk, 2),\n            'contributing_factors': self._identify_risk_factors(matches),\n            'mitigation_priority': self._prioritize_mitigation(matches)\n        }\n    \n    def _identify_risk_factors(self, matches: List[ThreatMatch]) -> List[str]:\n        \"\"\"Identify key risk factors from matches.\"\"\"\n        factors = set()\n        \n        for match in matches:\n            if match.indicator.threat_level == ThreatLevel.CRITICAL:\n                factors.add('Critical threat level indicators present')\n            \n            if match.indicator.threat_type == ThreatType.MALWARE:\n                factors.add('Malware indicators detected')\n            elif match.indicator.threat_type == ThreatType.PHISHING:\n                factors.add('Phishing indicators detected')\n            elif match.indicator.threat_type == ThreatType.BOTNET:\n                factors.add('Botnet activity indicators')\n            \n            if match.confidence_score > 0.8:\n                factors.add('High confidence threat intelligence')\n            \n            if match.indicator.ioc_type.value == 'file_hash':\n                factors.add('Malicious file signatures detected')\n        \n        return list(factors)\n    \n    def _prioritize_mitigation(self, matches: List[ThreatMatch]) -> List[Dict[str, Any]]:\n        \"\"\"Prioritize mitigation actions.\"\"\"\n        priorities = []\n        \n        # Sort matches by risk score\n        sorted_matches = sorted(matches, key=lambda m: m.risk_score, reverse=True)\n        \n        for i, match in enumerate(sorted_matches[:5]):  # Top 5 priorities\n            priority = {\n                'rank': i + 1,\n                'indicator': match.indicator.value,\n                'threat_type': match.indicator.threat_type.value,\n                'risk_score': match.risk_score,\n                'recommended_action': self._get_recommended_action(match)\n            }\n            priorities.append(priority)\n        \n        return priorities\n    \n    def _get_recommended_action(self, match: ThreatMatch) -> str:\n        \"\"\"Get recommended action for a threat match.\"\"\"\n        ioc_type = match.indicator.ioc_type.value\n        threat_type = match.indicator.threat_type.value\n        \n        if ioc_type == 'ip_address':\n            return 'Block IP address in firewall and monitor network traffic'\n        elif ioc_type == 'domain':\n            return 'Block domain in DNS and web filtering systems'\n        elif ioc_type == 'url':\n            return 'Block URL in web filtering and email security systems'\n        elif ioc_type == 'file_hash':\n            return 'Add hash to antivirus signatures and scan systems'\n        elif ioc_type == 'email':\n            return 'Block sender in email security systems'\n        else:\n            return 'Investigate and implement appropriate controls'\n    \n    async def _generate_recommendations(self, matches: List[ThreatMatch]) -> List[str]:\n        \"\"\"Generate security recommendations based on matches.\"\"\"\n        recommendations = set()\n        \n        # General recommendations\n        if matches:\n            recommendations.add('Implement continuous threat monitoring')\n            recommendations.add('Update threat intelligence feeds regularly')\n            recommendations.add('Review and update security controls')\n        \n        # Specific recommendations based on threat types\n        threat_types = {match.indicator.threat_type for match in matches}\n        \n        if ThreatType.MALWARE in threat_types:\n            recommendations.add('Deploy advanced endpoint detection and response (EDR)')\n            recommendations.add('Implement application whitelisting')\n            recommendations.add('Regular malware signature updates')\n        \n        if ThreatType.PHISHING in threat_types:\n            recommendations.add('Enhance email security controls')\n            recommendations.add('Implement user security awareness training')\n            recommendations.add('Deploy anti-phishing solutions')\n        \n        if ThreatType.BOTNET in threat_types:\n            recommendations.add('Monitor network traffic for C2 communications')\n            recommendations.add('Implement network segmentation')\n            recommendations.add('Deploy network-based threat detection')\n        \n        # IOC-specific recommendations\n        ioc_types = {match.indicator.ioc_type for match in matches}\n        \n        if any(ioc.value in ['ip_address', 'domain', 'url'] for ioc in ioc_types):\n            recommendations.add('Implement DNS filtering and monitoring')\n            recommendations.add('Deploy web application firewall (WAF)')\n        \n        return list(recommendations)\n    \n    def _calculate_enrichment_confidence(self, context: ThreatContext) -> float:\n        \"\"\"Calculate confidence score for enrichment.\"\"\"\n        base_confidence = 0.5\n        \n        # Increase confidence based on number of enrichment sources\n        source_bonus = len(context.enrichment_sources) * 0.1\n        \n        # Increase confidence based on available context\n        context_bonus = 0.0\n        if context.malware_families:\n            context_bonus += 0.1\n        if context.threat_actors:\n            context_bonus += 0.15\n        if context.campaigns:\n            context_bonus += 0.1\n        if context.techniques:\n            context_bonus += 0.1\n        \n        total_confidence = base_confidence + source_bonus + context_bonus\n        return min(total_confidence, 1.0)\n    \n    def _load_mitre_attack_db(self) -> Dict[str, Any]:\n        \"\"\"Load MITRE ATT&CK database (placeholder).\"\"\"\n        # In a real implementation, this would load from MITRE ATT&CK data\n        return {\n            'techniques': {\n                'T1071.001': {\n                    'name': 'Application Layer Protocol: Web Protocols',\n                    'tactics': ['command-and-control']\n                },\n                'T1090': {\n                    'name': 'Proxy',\n                    'tactics': ['command-and-control']\n                },\n                'T1102': {\n                    'name': 'Web Service',\n                    'tactics': ['command-and-control']\n                },\n                'T1055': {\n                    'name': 'Process Injection',\n                    'tactics': ['defense-evasion', 'privilege-escalation']\n                },\n                'T1059': {\n                    'name': 'Command and Scripting Interpreter',\n                    'tactics': ['execution']\n                },\n                'T1566.001': {\n                    'name': 'Phishing: Spearphishing Attachment',\n                    'tactics': ['initial-access']\n                },\n                'T1566.002': {\n                    'name': 'Phishing: Spearphishing Link',\n                    'tactics': ['initial-access']\n                }\n            }\n        }\n    \n    def _load_malware_db(self) -> Dict[str, Any]:\n        \"\"\"Load malware database (placeholder).\"\"\"\n        return {\n            'families': [\n                'Emotet', 'TrickBot', 'Ryuk', 'Cobalt Strike',\n                'Mimikatz', 'PowerShell Empire', 'Metasploit',\n                'Zeus', 'Dridex', 'IcedID', 'Qakbot'\n            ]\n        }\n    \n    def _load_actor_db(self) -> Dict[str, Any]:\n        \"\"\"Load threat actor database (placeholder).\"\"\"\n        return {\n            'actors': {\n                'APT29': {\n                    'countries': ['Russia'],\n                    'tactics': ['initial-access', 'persistence', 'lateral-movement'],\n                    'iocs': []\n                },\n                'APT28': {\n                    'countries': ['Russia'],\n                    'tactics': ['initial-access', 'credential-access'],\n                    'iocs': []\n                }\n            }\n        }\n    \n    def _load_campaign_db(self) -> Dict[str, Any]:\n        \"\"\"Load campaign database (placeholder).\"\"\"\n        return {\n            'campaigns': {\n                'SolarWinds': {\n                    'start_date': '2020-03-01',\n                    'end_date': '2020-12-31',\n                    'description': 'Supply chain attack targeting SolarWinds Orion',\n                    'iocs': []\n                }\n            }\n        }